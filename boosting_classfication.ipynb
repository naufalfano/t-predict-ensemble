{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76eda1b8",
   "metadata": {},
   "source": [
    "## Codebase for bank marketing dataset classification using boosting techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0927d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f22e73d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age        job  marital    education  default housing loan    contact  \\\n",
      "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
      "1   57   services  married  high.school  unknown      no   no  telephone   \n",
      "2   37   services  married  high.school       no     yes   no  telephone   \n",
      "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
      "4   56   services  married  high.school       no      no  yes  telephone   \n",
      "\n",
      "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
      "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "\n",
      "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
      "0          93.994          -36.4      4.857       5191.0  no  \n",
      "1          93.994          -36.4      4.857       5191.0  no  \n",
      "2          93.994          -36.4      4.857       5191.0  no  \n",
      "3          93.994          -36.4      4.857       5191.0  no  \n",
      "4          93.994          -36.4      4.857       5191.0  no  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "from dataset import get_data\n",
    "\n",
    "df = get_data()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a530364c",
   "metadata": {},
   "source": [
    "Pipeline preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6acb5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "def preprocessing_pipeline(X, y, test_size=0.3, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    smote_tomek = SMOTETomek(random_state=random_state)\n",
    "    X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_resampled, X_test, y_resampled, y_test\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50b4fee",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677a8026",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea03f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8599\n",
      "Recall: 0.8405\n",
      "Precision: 0.4367\n",
      "F1 Score: 0.5748\n",
      "Confusion Matrix: TN=9456, FP=1509, FN=222, TP=1170\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "X_resampled, X_test, y_resampled, y_test, encoders, scalers = preprocessing_pipeline(df)\n",
    "\n",
    "lr = LogisticRegression(max_iter=100, random_state=42)\n",
    "lr.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "182ef57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8600\n",
      "Recall: 0.8405\n",
      "Precision: 0.4369\n",
      "F1 Score: 0.5749\n",
      "Confusion Matrix: TN=9457, FP=1508, FN=222, TP=1170\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from preprocessing import *\n",
    "\n",
    "X_resampled, X_test, y_resampled, y_test, encoders, scalers = preprocessing_pipeline(df)\n",
    "\n",
    "lr = LogisticRegression(max_iter=100, random_state=42)\n",
    "lr.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a727ace",
   "metadata": {},
   "source": [
    "### Boosting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d986f5",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb61422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8717\n",
      "Recall: 0.8218\n",
      "Precision: 0.4609\n",
      "F1 Score: 0.5906\n",
      "Confusion Matrix: TN=9627, FP=1338, FN=248, TP=1144\n"
     ]
    }
   ],
   "source": [
    "#Base Model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "X_resampled, X_test, y_resampled, y_test = preprocessing_pipeline(X, y)\n",
    "\n",
    "adb = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "adb.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = adb.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e4d61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 1.0, 'n_estimators': 500}\n",
      "Accuracy: 0.8943\n",
      "Recall: 0.7522\n",
      "Precision: 0.5214\n",
      "F1 Score: 0.6159\n",
      "Confusion Matrix: TN=10004, FP=961, FN=345, TP=1047\n"
     ]
    }
   ],
   "source": [
    "#Optimized Model GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "X_resampled, X_test, y_resampled, y_test = preprocessing_pipeline(X, y)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'learning_rate': [ 0.01, 0.1, 0.3, 0.5, 1.0],\n",
    "}\n",
    "\n",
    "adb = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(adb, param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "best_adb = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "opt_adb = AdaBoostClassifier(n_estimators=best_adb.n_estimators, learning_rate=best_adb.learning_rate, random_state=42)\n",
    "opt_adb.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = opt_adb.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a0ac61",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40517d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8832\n",
      "Recall: 0.8463\n",
      "Precision: 0.4894\n",
      "F1 Score: 0.6202\n",
      "Confusion Matrix: TN=9736, FP=1229, FN=214, TP=1178\n"
     ]
    }
   ],
   "source": [
    "#Base Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "X_resampled, X_test, y_resampled, y_test = preprocessing_pipeline(X, y)\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3f2f25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Accuracy: 0.9120\n",
      "Recall: 0.6466\n",
      "Precision: 0.6020\n",
      "F1 Score: 0.6235\n",
      "Confusion Matrix: TN=10370, FP=595, FN=492, TP=900\n"
     ]
    }
   ],
   "source": [
    "#Optimized Model using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "X_resampled, X_test, y_resampled, y_test = preprocessing_pipeline(X, y)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5, 1.0],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(gb, param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "best_gb = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "opt_gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_gb.n_estimators,\n",
    "    learning_rate=best_gb.learning_rate,\n",
    "    max_depth=best_gb.max_depth,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "opt_gb.fit(X_resampled, y_resampled)\n",
    "y_pred = opt_gb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7118ed65",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6ca0abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9119\n",
      "Recall: 0.6825\n",
      "Precision: 0.5949\n",
      "F1 Score: 0.6357\n",
      "Confusion Matrix: TN=10318, FP=647, FN=442, TP=950\n"
     ]
    }
   ],
   "source": [
    "#Base Model\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "X_resampled, X_test, y_resampled, y_test = preprocessing_pipeline(X, y)\n",
    "\n",
    "xgb = xgb.XGBClassifier(tree_method=\"hist\", device=\"cuda\", random_state=42)\n",
    "xgb.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0add25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'n_estimators': 500, 'subsample': 0.8}\n",
      "Accuracy: 0.9113862588006798\n",
      "Recall: 0.6436781609195402\n",
      "Precision: 0.5993311036789297\n",
      "F1 Score: 0.6207135434707308\n",
      "Confusion Matrix:\n",
      "[[10366   599]\n",
      " [  496   896]]\n"
     ]
    }
   ],
   "source": [
    "#Optimized Model GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from preprocessing import *\n",
    "\n",
    "X_resampled, X_test, y_resampled, y_test, encoders, scalers = preprocessing_pipeline(df)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'learning_rate': [ 0.01, 0.1, 0.3, 0.5, 1.0],\n",
    "    'subsample': [0.5, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgbc = xgb.XGBClassifier(tree_method=\"hist\", device=\"cuda\", random_state=42)\n",
    "grid_search = GridSearchCV(xgbc, param_grid, cv=cv_5fold, scoring='f1', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "best_xgb = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "opt_xgb = xgb.XGBClassifier(\n",
    "    n_estimators=best_xgb.n_estimators,\n",
    "    learning_rate=best_xgb.learning_rate,\n",
    "    max_depth=best_xgb.max_depth,\n",
    "    subsample=best_xgb.subsample,\n",
    "    tree_method=\"hist\",\n",
    "    device=\"cuda\",\n",
    "    random_state=42\n",
    ")\n",
    "opt_xgb.fit(X_resampled, y_resampled)\n",
    "y_pred = opt_xgb.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "tp, fn, fp, tn = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Recall: {rec}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9430e5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'n_estimators': 500, 'subsample': 0.5}\n",
      "Accuracy: 0.910091446143886\n",
      "Recall: 0.6429597701149425\n",
      "Precision: 0.5931080185553347\n",
      "F1 Score: 0.6170286108238539\n",
      "Confusion Matrix: TN=895, FP=497, FN=614, TP=10351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\edu\\t-predict-ensemble\\venv\\Lib\\site-packages\\xgboost\\core.py:729: UserWarning: [12:08:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Optimized Model GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from preprocessing import *\n",
    "\n",
    "X_resampled, X_test, y_resampled, y_test, encoders, scalers = preprocessing_pipeline(df)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'learning_rate': [ 0.01, 0.1, 0.3, 0.5, 1.0],\n",
    "    'subsample': [0.5, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgbc = xgb.XGBClassifier(tree_method=\"hist\", device=\"cuda\", random_state=42)\n",
    "grid_search = GridSearchCV(xgbc, param_grid, cv=cv_5fold(), scoring='f1', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "best_xgb = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "opt_xgb = xgb.XGBClassifier(\n",
    "    n_estimators=best_xgb.n_estimators,\n",
    "    learning_rate=best_xgb.learning_rate,\n",
    "    max_depth=best_xgb.max_depth,\n",
    "    subsample=best_xgb.subsample,\n",
    "    tree_method=\"hist\",\n",
    "    device=\"cuda\",\n",
    "    random_state=42\n",
    ")\n",
    "opt_xgb.fit(X_resampled, y_resampled)\n",
    "y_pred = opt_xgb.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "tp, fn, fp, tn = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Recall: {rec}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
